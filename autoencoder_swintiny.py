# -*- coding: utf-8 -*-
"""Autoencoder_SwinTiny.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1rLIxxxK3mEzX6D0wYCM9AQklzi1mEKTH
"""

!pip install timm


import torch
import torch.nn as nn
import torch.optim as optim
import torchvision.transforms as transforms
import timm
from torch.utils.data import DataLoader, Dataset
from google.colab import drive
import numpy as np
import os
import cv2
from skimage.metrics import peak_signal_noise_ratio as psnr
from skimage.metrics import structural_similarity as ssim
from sklearn.metrics import mean_absolute_error as mae
import matplotlib.pyplot as plt


drive.mount('/content/gdrive')

dataset_path = '/content/gdrive/My Drive/Liang/autoencoder_img'
flip_path = os.path.join(dataset_path, 'flip')
normal_path = os.path.join(dataset_path, 'normal')
normal200_path = os.path.join(dataset_path, 'normal200')

def load_images(folder):
    images = []
    for filename in os.listdir(folder):
        img = cv2.imread(os.path.join(folder, filename))
        if img is not None:
            img = cv2.resize(img, (224, 224))
            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
            img = img / 255.0
            images.append(img)
    return np.array(images, dtype=np.float32)

flip_images = load_images(flip_path)
normal_images = load_images(normal_path)
normal200_images = load_images(normal200_path)

normal_images_combined = np.concatenate((normal_images, normal200_images), axis=0)

class AutoencoderDataset(Dataset):
    def __init__(self, images, transform=None):
        self.images = images
        self.transform = transform

    def __len__(self):
        return len(self.images)

    def __getitem__(self, idx):
        img = self.images[idx]
        if self.transform:
            img = self.transform(img)
        return img

transform = transforms.Compose([
    transforms.ToTensor(),
])

dataset = AutoencoderDataset(normal_images_combined, transform=transform)

train_size = int(0.8 * len(dataset))
test_size = len(dataset) - train_size
train_dataset, test_dataset = torch.utils.data.random_split(dataset, [train_size, test_size])

train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)
test_loader = DataLoader(test_dataset, batch_size=16, shuffle=True)


device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")

class SwinTinyAutoencoder(nn.Module):
    def __init__(self):
        super(SwinTinyAutoencoder, self).__init__()
        swin_tiny = timm.create_model("swin_tiny_patch4_window7_224", pretrained=True)
        self.encoder = nn.Sequential(*list(swin_tiny.children())[:-1])
        self.decoder = nn.Sequential(
            nn.ConvTranspose2d(768, 384, kernel_size=4, stride=2, padding=1),
            nn.ReLU(inplace=True),
            nn.ConvTranspose2d(384, 96, kernel_size=1, stride=1, padding=0),
            nn.ReLU(inplace=True),
            nn.ConvTranspose2d(96, 192, kernel_size=4, stride=2, padding=1),
            nn.ReLU(inplace=True),
            nn.ConvTranspose2d(192, 48, kernel_size=1, stride=1, padding=0),
            nn.ReLU(inplace=True),
            nn.ConvTranspose2d(48, 96, kernel_size=4, stride=2, padding=1),
            nn.ReLU(inplace=True),
            nn.ConvTranspose2d(96, 24, kernel_size=1, stride=1, padding=0),
            nn.ReLU(inplace=True),
            nn.ConvTranspose2d(24, 48, kernel_size=4, stride=2, padding=1),
            nn.ReLU(inplace=True),
            nn.ConvTranspose2d(48, 12, kernel_size=1, stride=1, padding=0),
            nn.ReLU(inplace=True),
            nn.ConvTranspose2d(12, 3, kernel_size=4, stride=2, padding=1),
            nn.Sigmoid(),
            nn.Conv2d(3, 3, kernel_size=3, stride=1, padding=1, bias=False),
            nn.Conv2d(3, 3, kernel_size=3, stride=1, padding=1, bias=False),
            nn.Conv2d(3, 3, kernel_size=3, stride=1, padding=1, bias=False),
        )

    def forward(self, x):
        x = self.encoder(x)
        x = x.view(x.shape[0], 768, 7, 7)  # Reshape the output of the encoder
        x = self.decoder(x)
        return x




autoencoder = SwinTinyAutoencoder().to(device)
criterion = nn.MSELoss()
optimizer = optim.Adam(autoencoder.parameters(), lr=0.0001)

num_epochs = 50

for epoch in range(num_epochs):
    for inputs in train_loader:
        inputs = inputs.to(device)
        optimizer.zero_grad()
        outputs = autoencoder(inputs)
        loss = criterion(outputs, inputs)
        loss.backward()
        optimizer.step()

    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')

print('Training completed.')

autoencoder.eval()
total_loss = 0
total_psnr = 0
total_ssim = 0
total_mae = 0
with torch.no_grad():
    for inputs in test_loader:
        inputs = inputs.to(device)
        outputs = autoencoder(inputs)
        loss = criterion(outputs, inputs)
        total_loss += loss.item()

        inputs_np = inputs.cpu().numpy().transpose(0, 2, 3, 1)
        outputs_np = outputs.cpu().numpy().transpose(0, 2, 3, 1)

        for i in range(inputs_np.shape[0]):
            total_psnr += psnr(inputs_np[i], outputs_np[i], data_range=1)
            total_ssim += ssim(inputs_np[i], outputs_np[i], multichannel=True, data_range=1)
            total_mae += mae(inputs_np[i].flatten(), outputs_np[i].flatten())

average_loss = total_loss / len(test_loader)
average_psnr = total_psnr / (len(test_loader) * test_loader.batch_size)
average_ssim = total_ssim / (len(test_loader) * test_loader.batch_size)
average_mae = total_mae / (len(test_loader) * test_loader.batch_size)

print(f'Average Test Loss: {average_loss:.4f}')
print(f'Average Test PSNR: {average_psnr:.4f}')
print(f'Average Test SSIM: {average_ssim:.4f}')
print(f'Average Test MAE: {average_mae:.4f}')

def display_images(original, decoded, image_ids, num_images=5):
    plt.figure(figsize=(2*num_images, 4))
    for i in range(num_images):
        # Display image ID
        plt.text(i*2+0.5, 0.05, f'Image {image_ids[i]}', fontsize=10, ha='center')

        # Display original images
        ax = plt.subplot(2, num_images, i + 1)
        plt.imshow(original[i])
        ax.get_xaxis().set_visible(False)
        ax.get_yaxis().set_visible(False)

        # Display reconstructed images
        ax = plt.subplot(2, num_images, i + 1 + num_images)
        plt.imshow(decoded[i])
        ax.get_xaxis().set_visible(False)
        ax.get_yaxis().set_visible(False)
    plt.show()



# Get a batch of test images and their reconstructions
test_iter = iter(test_loader)
inputs = next(test_iter).to(device)
with torch.no_grad():
    outputs = autoencoder(inputs)

# Convert the tensors back to NumPy and transpose the dimensions for display
original_images = inputs.cpu().numpy().transpose(0, 2, 3, 1)
decoded_images = outputs.cpu().numpy().transpose(0, 2, 3, 1)

# Get the image IDs from the test dataset
image_ids = [test_dataset.indices[i] for i in range(test_loader.batch_size)]

# Display the images
display_images(original_images, decoded_images, image_ids)